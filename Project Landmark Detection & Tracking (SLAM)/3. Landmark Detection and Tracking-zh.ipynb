{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实战项目3：实现SLAM \n",
    "\n",
    "---\n",
    "\n",
    "## 项目概述\n",
    "\n",
    "在这个项目中，你将要在一个2维网格世界中使一个会移动与感测的机器人实现SLAM（实时定位与地图构建）！\n",
    "\n",
    "当这个机器人进行实时移动和感测时，SLAM为我们提供了一种用于定位机器人并构建其所在环境的地图的一种方法。这是机器人与自动系统领域一个非常活跃的研究领域。由于这种定位和地图构建依赖于地标的视觉感知，因此属于计算机视觉范畴。\n",
    "\n",
    "接下来，你需要使用之前所学的机器人运动、运动与感测中的不确定性表示以及定位技术，定义一个函数`slam`，它需要接收六个参数作为输入并返回矢量`mu`。\n",
    ">   `mu`包含机器人移动时的坐标位置（x，y）以及它在该空间感测到的地标位置\n",
    "\n",
    "你可以根据需要实现几个辅助函数，但是这些函数必须返回`mu`。矢量`mu`应该包含交错的坐标（x，y），例如，如果有2个姿势和2个地标，`mu`将如下所示，其中`P`表示机器人位置，`L`表示地标位置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu =  matrix([[Px0],\n",
    "              [Py0],\n",
    "              [Px1],\n",
    "              [Py1],\n",
    "              [Lx0],\n",
    "              [Ly0],\n",
    "              [Lx1],\n",
    "              [Ly1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以看到，`mu`首先会保持这些位置的姿势`(x0, y0), (x1, y1), ...,`......，然后是矩阵末端的地标位置。在里，我们可以把`nx1`矩阵当做是一个向量。\n",
    "\n",
    "## 创建一个环境\n",
    "\n",
    "在真实的SLAM问题中，你可能会获得一个包含有关地标位置信息的地图，而在这个示例中，我们将使用`make_data`函数创建自己的数据，该函数会生成一个带有地标的二维空间网格，然后把一个机器人放置在该空间中，并通过其在一些时间步内的移动和感知来生成数据。`make_data`函数依赖于机器人移动与感知函数的正确实现，此时应该已完成实现，并且保存在`robot_class.py` 文件中。实例化的机器人在该世界中移动和感测的过程中，会自动收集数据，而你的SLAM函数需要接收此数据作为输入。因此，我们首先要做的是创建这些数据，然后研究它是如何表示机器人所做的运动和传感器测量。\n",
    "\n",
    "---\n",
    "\n",
    "## 创建该世界\n",
    "\n",
    "使用下面的代码生成一个指定大小的世界，其中的地标位置是随机生成的。你可以更改这些参数，然后观察一下你的SLAM实现会发生怎样的变化吧！\n",
    "\n",
    "`data`会保存传感器测量值和机器人随时间的运动数据。它会分别将测量值存储为`data[i][0]`，将运动存储为`data[i][1]`。\n",
    "\n",
    "#### 辅助函数\n",
    "\n",
    "接下来，你要使用的是`robot`类，这个类看起来是不是和第一个notebook中的类很相似？\n",
    "\n",
    "实际上，在`helpers.py`文件中，你可以阅读有关如何使用`make_data`函数来创建数据的详细信息。这一点与你在第一个notebook中看到的机器人移动与感测循环部分非常相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import make_data\n",
    "\n",
    "# your implementation of slam should work with the following inputs\n",
    "# feel free to change these input values and see how it responds!\n",
    "\n",
    "# world parameters\n",
    "num_landmarks      = 5        # number of landmarks\n",
    "N                  = 20       # time steps\n",
    "world_size         = 100.0    # size of world (square)\n",
    "\n",
    "# robot parameters\n",
    "measurement_range  = 50.0     # range at which we can sense landmarks\n",
    "motion_noise       = 2.0      # noise in robot motion\n",
    "measurement_noise  = 2.0      # noise in the measurements\n",
    "distance           = 20.0     # distance by which robot (intends to) move each iteratation \n",
    "\n",
    "\n",
    "# make_data instantiates a robot, AND generates random landmarks for a given world size and number of landmarks\n",
    "data = make_data(N, num_landmarks, world_size, measurement_range, motion_noise, measurement_noise, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关于`make_data`的说明\n",
    "\n",
    "上面的`make_data`函数会接收许多关于世界和机器人的运动与传感器参数，因为它需要完成下列任务：\n",
    "1. 将机器人实例化 （使用 robot 类）\n",
    "2. 创建一个包含地标的网格世界\n",
    "\n",
    "**此函数还会输出地标的真实位置和机器人的 *最终*位置，在测试SLAM的实现时应该参考这些位置。**\n",
    "\n",
    "返回的`data`是一个数组，其中包含有关**机器人传感器测量**和**机器人运动** `(dx, dy)`的信息，这些信息是在多个时间步`N`内收集的。你*只*需使用这些关于运动和测量的读数来根据时间跟踪这个机器人，然后使用SLAM找到地标确定的位置。我们只需要输出真实的地标位置即可，便于稍后进行比较。\n",
    "\n",
    "\n",
    "在`data`中，可以从数据组的列中的第一个和第二个索引访问测量与运动数据。有关示例，请参阅以下代码，其中`i`是时间步："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement = data[i][0]\n",
    "motion = data[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out some stats about the data\n",
    "time_step = 0\n",
    "\n",
    "print('Example measurements: \\n', data[time_step][0])\n",
    "print('\\n')\n",
    "print('Example motion: \\n', data[time_step][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试更改`time_step`的值，你应该看到测量值列表会根据机器人移动后看到的世界的不同而不同。在第一个notebook中，我们已经了解到，机器人只能感知到这么远，并且在测量其位置和地标位置之间的距离方面具有一定的准确性。机器人的运动始终是具有两个值的向量：一个是x位移，一个是y位移。在实现SLAM，遍历此数据时，请记住此结构。\n",
    "\n",
    "## 初始化约束\n",
    "\n",
    "在这里，最具挑战性的任务是创建和修改约束矩阵与和向量：omega和xi。在第二个notebook中，我们看过一个例子，那个例子说明的是omega和xi如何能够保存所有值，如何定义机器人一维世界中的机器人姿势`xi`和地标位置`Li`之间的关系，如下所示，其中omega是蓝色矩阵，xi是粉色矢量。\n",
    "\n",
    "<img src='images/motion_constraint.png' width=50% height=50% />\n",
    "\n",
    "\n",
    " 而在*这个*项目中，你的任务是实现一个二维世界的约束。我们将机器人姿势表示为`Px, Py`，将地标位置表示为`Lx, Ly`。要完成这个任务，这里有一种方法，即在约束矩阵中添加x*和*y位置。\n",
    "\n",
    "<img src='images/constraints2D.png' width=50% height=50% />\n",
    "\n",
    "当然了，你也可以选择为每个omega和xi分别创建两个值（一个是x位置，一个是y位置）。\n",
    "\n",
    "### TODO: 编写一个用于初始化omega和xi的函数\n",
    "\n",
    "完成函数`initialize_constraints` ，使其返回机器人起始位置的`omega`和`xi`约束。 我们还不知道的任何值都应该用值`0` 来初始化。你可以假设我们的机器人在置信度为100%的情况下从这个世界的中心位置开始出发（此时没有移动或测量噪声）。 通过输入值时间步`N`、`num_landmarks`与`world_size`， 你就可以获得构建正确大小和起始值的初始约束所需的所有信息。\n",
    "\n",
    "*你可以选择返回一个omega和一个xi，其中包含所有（x，y）位置 *或* 每个中的两个（一个是x值，一个是y），也可以选择你觉得有效的方法。具体怎么选择，由你来决定哦！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_constraints(N, num_landmarks, world_size):\n",
    "    ''' This function takes in a number of time steps N, number of landmarks, and a world_size,\n",
    "        and returns initialized constraint matrices, omega and xi.'''\n",
    "    \n",
    "    ## Recommended: Define and store the size (rows/cols) of the constraint matrix in a variable\n",
    "    \n",
    "    ## TODO: Define the constraint matrix, Omega, with two initial \"strength\" values\n",
    "    ## for the initial x, y location of our robot\n",
    "    omega = [0]\n",
    "    \n",
    "    ## TODO: Define the constraint *vector*, xi\n",
    "    ## you can assume that the robot starts out in the middle of the world with 100% confidence\n",
    "    xi = [0]\n",
    "    \n",
    "    return omega, xi\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在创建的过程中进行测试\n",
    "\n",
    "在创建的过程中进行测试，这个是个好习惯。要说明机器人传感器测量和运动，`slam`需要依赖于创建与更新约束矩阵omega和xi，所以，我们要检查它们是否按预期为所有给定参数初始化。\n",
    "\n",
    "下面，你会找到一些用于将函数`initialize_constraints`结果可视化的测试代码。在这里，要使用 [seaborn](https://seaborn.pydata.org/) 库进行可视化。\n",
    "\n",
    "**请更改N、landmarks和world_size的测试值并查看结果**。注意，不要将这些值用作最终的slam函数（译者注：原文是smal，但这里应该是slam）的输入。\n",
    "\n",
    "此代码会假定你已创建了每个约束`omega` 与 `xi`中的一个值，但你还可以相应地做更改并添加到此代码中。约束的大小应随时间步和地标的数量而变化，因为这些值会影响机器人将使用的姿势数量`(Px0,Py0,...Pxn,Pyn)`和地标位置`(Lx0,Ly0,...Lxn,Lyn)`， 其关系应该在约束矩阵中跟踪。回想一下之前所学的知识，`omega`保存每个变量的权重，而`xi`保存这些变量之和的值，如Notebook 2中所示。你需要使用`world_size`来确定该世界中机器人的起始姿势并填写`xi`的初始值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data viz resources\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a small N and world_size (small for ease of visualization)\n",
    "N_test = 5\n",
    "num_landmarks_test = 2\n",
    "small_world = 10\n",
    "\n",
    "# initialize the constraints\n",
    "initial_omega, initial_xi = initialize_constraints(N_test, num_landmarks_test, small_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "\n",
    "# display omega\n",
    "sns.heatmap(DataFrame(initial_omega), cmap='Blues', annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define  figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (1,7)\n",
    "\n",
    "# display xi\n",
    "sns.heatmap(DataFrame(initial_xi), cmap='Oranges', annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SLAM输入 \n",
    "\n",
    "除了`data`，SLAM函数还需要接收以下输入：\n",
    "* N -   机器人将要移动和感测的时间步数\n",
    "* num_landmarks - 该世界中的地标数量\n",
    "* world_size - 该世界的大小（宽度 / 高度）\n",
    "* motion_noise - 与运动相关的噪声；运动的更新置信度应为`1.0/motion_noise`\n",
    "* measurement_noise - 与测量/感测相关的噪声；测量的更新权重应为`1.0/measurement_noise`\n",
    "\n",
    "#### 关于噪声的说明\n",
    "\n",
    "回想一下之前所学的内容，`omega`保存每个位置变量的相对“强度”或权重，你可以通过访问omega `omega[row][col]`中的正确索引并在`noise`为测量值或运动噪声的情况下 *添加/减去*`1.0/noise`来更新这些权重。 `xi`会保存实际的位置值，因此为了更新`xi`，你只需要使用运动或测量的实际值来实现类似的添加过程。因此，对于矢量索引`xi[row][0]`，你最终要做的是添加/减去一个测量或运动值，然后除以它们各自的`noise`。\n",
    "\n",
    "### TODO: 实现Graph SLAM\n",
    "\n",
    "按照下面的指示，完成SLAM的实现（我们建议你按照这些TODO的顺序来操作），然后测试实现效果吧！\n",
    "\n",
    "#### 通过运动和测量进行更新\n",
    "\n",
    "使用如上所示的2D omega和xi结构（在之前的单元格中），你必须要注意的是如何更新这些约束矩阵中的值才能说明x和y方向上的运动和测量约束。回想一下这些矩阵（包含机器人姿势`P`和地标位置`L`的所有值）的解决方法在于向量`mu`，而`mu`可以在omega和xi构造结束时计算为omega乘以xi的倒数： $\\mu = \\Omega^{-1}\\xi$\n",
    "\n",
    "**如果想要显示最终状态，你也可以选择返回`omega`和`xi`的值！**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Complete the code to implement SLAM\n",
    "\n",
    "## slam takes in 6 arguments and returns mu, \n",
    "## mu is the entire path traversed by a robot (all x,y poses) *and* all landmarks locations\n",
    "def slam(data, N, num_landmarks, world_size, motion_noise, measurement_noise):\n",
    "    \n",
    "    ## TODO: Use your initilization to create constraint matrices, omega and xi\n",
    "    \n",
    "    ## TODO: Iterate through each time step in the data\n",
    "    ## get all the motion and measurement data as you iterate\n",
    "            \n",
    "    ## TODO: update the constraint matrix/vector to account for all *measurements*\n",
    "    ## this should be a series of additions that take into account the measurement noise\n",
    "            \n",
    "    ## TODO: update the constraint matrix/vector to account for all *motion* and motion noise\n",
    "    \n",
    "    ## TODO: After iterating through all the data\n",
    "    ## Compute the best estimate of poses and landmark positions\n",
    "    ## using the formula, omega_inverse * Xi\n",
    "    mu = None\n",
    "    \n",
    "    return mu # return `mu`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 辅助函数\n",
    "\n",
    " 为了检查你的SLAM实现是否适用于各种输入，我们提供了两个辅助函数，可用于帮助显示函数生成的估计姿势和地标位置。首先，给定一个结果`mu`和时间步`N`，然后，定义一个提取姿势和地标位置的函数，并将它们作为自己的单独列表返回。\n",
    "\n",
    "最后，定义一个能够很好地输出这些列表的函数。我们将在下一步中调用这两个辅助函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function that creates a list of poses and of landmarks for ease of printing\n",
    "# this only works for the suggested constraint architecture of interlaced x,y poses\n",
    "def get_poses_landmarks(mu, N):\n",
    "    # create a list of poses\n",
    "    poses = []\n",
    "    for i in range(N):\n",
    "        poses.append((mu[2*i].item(), mu[2*i+1].item()))\n",
    "\n",
    "    # create a list of landmarks\n",
    "    landmarks = []\n",
    "    for i in range(num_landmarks):\n",
    "        landmarks.append((mu[2*(N+i)].item(), mu[2*(N+i)+1].item()))\n",
    "\n",
    "    # return completed lists\n",
    "    return poses, landmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_all(poses, landmarks):\n",
    "    print('\\n')\n",
    "    print('Estimated Poses:')\n",
    "    for i in range(len(poses)):\n",
    "        print('['+', '.join('%.3f'%p for p in poses[i])+']')\n",
    "    print('\\n')\n",
    "    print('Estimated Landmarks:')\n",
    "    for i in range(len(landmarks)):\n",
    "        print('['+', '.join('%.3f'%l for l in landmarks[i])+']')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行SLAM\n",
    "\n",
    " `slam` 实现以后，看一看对于不同的空间大小和不同的地标，它会返回什么`mu`值吧！\n",
    "\n",
    "### 预期的结果是什么\n",
    "\n",
    "虽然生成的`data`是随机的，但你之前确实需要指定机器人预期移动的数量或时间步`N`以及该二维空间中的`num_landmarks`。而在这个空间中，你实现的`slam`应该能够预测到一个位置，也应该可以从该方形空间的正中心开始估计姿势，而这个方形空间的大小由`world_size`定义。\n",
    "\n",
    "考虑到这些值，你预期看到的结果应该会显示两个列表：\n",
    "1. **Estimated poses**： 一个（x，y）对的列表，其长度恰好为`N`，因为这是你的机器人所做的运动次数。第一个姿势应该是该二维空间的中心，对于一个方形大小为100.0的世界，这个坐标是`[50.000, 50.000]`。\n",
    "2. **Estimated landmarks**： 一个地标位置列表（x，y），其长度恰好是`num_landmarks`。\n",
    "\n",
    "#### 地标位置\n",
    "\n",
    "如果在创建此数据时回头查看一下*确切*地标位置的输出数据，你应该会发现那些数据与这些坐标非常相似，但不完全一致，因为`slam`必须考虑运动和测量中的噪声。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call your implementation of slam, passing in the necessary parameters\n",
    "mu = slam(data, N, num_landmarks, world_size, motion_noise, measurement_noise)\n",
    "\n",
    "# print out the resulting landmarks and poses\n",
    "if(mu is not None):\n",
    "    # get the lists of poses and landmarks\n",
    "    # and print them out\n",
    "    poses, landmarks = get_poses_landmarks(mu, N)\n",
    "    print_all(poses, landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将构建的世界可视化\n",
    "\n",
    "最后一步，要使用的是`helpers.py`文件（该文件在第一个notebook中曾使用过）中的`display_world`代码，我们实际上可以将`slam`编码的内容可视化，该内容包括由运动与测量数据创建的机器人最终位置和地标位置！\n",
    "\n",
    "**请注意，这些应该与我们在此notebook中之前调用`make_data`时输出的*真实*地标位置和最终姿势非常相似。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the helper function\n",
    "from helpers import display_world\n",
    "\n",
    "# Display the final world!\n",
    "\n",
    "# define figure size\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "# check if poses has been created\n",
    "if 'poses' in locals():\n",
    "    # print out the last pose\n",
    "    print('Last pose: ', poses[-1])\n",
    "    # display the last position of the robot *and* the landmark positions\n",
    "    display_world(int(world_size), poses[-1], landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题：*真实的*的最终姿势，与你根据`slam`预测的最终姿势相距有多远？你认为，为什么会产生这种差异？\n",
    "\n",
    "你可以在调用`make_data`的第一个单元格中找到最终姿势的真实值。你可能还想查看真实的地标位置，并将它们与`slam`估计的位置进行比较。在这里，请尝试思考一下：如果我们做更多移动（增加N），你认为会发生什么？或者，如果噪声参数更低或更高，会出现什么样的结果？\n",
    "\n",
    "**答案**: (请在这里写下你的答案。）\n",
    "\n",
    "## 测试\n",
    "\n",
    "要在提交项目之前确认你的slam代码是有效的，因此，我们建议你通过某些测试数据和示例来尝试运行一下。在下面的单元格中，我们为你提供了一些此类测试用例。准备就绪后，在下一个单元格中取消注释测试用例（这里总共有两个测试用例）。你的输出应该与给定结果**接近或完全相同**。如果存在微小差异，则可能是浮点精度问题或逆矩阵的计算问题。\n",
    "\n",
    "### 提交项目\n",
    "\n",
    "如果通过了这些测试，表明你的项目将通过项目审阅标准中的所有要求。按照提交说明正式提交吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the data and estimated outputs for test case 1\n",
    "\n",
    "test_data1 = [[[[1, 19.457599255548065, 23.8387362100849], [2, -13.195807561967236, 11.708840328458608], [3, -30.0954905279171, 15.387879242505843]], [-12.2607279422326, -15.801093326936487]], [[[2, -0.4659930049620491, 28.088559771215664], [4, -17.866382374890936, -16.384904503932]], [-12.2607279422326, -15.801093326936487]], [[[4, -6.202512900833806, -1.823403210274639]], [-12.2607279422326, -15.801093326936487]], [[[4, 7.412136480918645, 15.388585962142429]], [14.008259661173426, 14.274756084260822]], [[[4, -7.526138813444998, -0.4563942429717849]], [14.008259661173426, 14.274756084260822]], [[[2, -6.299793150150058, 29.047830407717623], [4, -21.93551130411791, -13.21956810989039]], [14.008259661173426, 14.274756084260822]], [[[1, 15.796300959032276, 30.65769689694247], [2, -18.64370821983482, 17.380022987031367]], [14.008259661173426, 14.274756084260822]], [[[1, 0.40311325410337906, 14.169429532679855], [2, -35.069349468466235, 2.4945558982439957]], [14.008259661173426, 14.274756084260822]], [[[1, -16.71340983241936, -2.777000269543834]], [-11.006096015782283, 16.699276945166858]], [[[1, -3.611096830835776, -17.954019226763958]], [-19.693482634035977, 3.488085684573048]], [[[1, 18.398273354362416, -22.705102332550947]], [-19.693482634035977, 3.488085684573048]], [[[2, 2.789312482883833, -39.73720193121324]], [12.849049222879723, -15.326510824972983]], [[[1, 21.26897046581808, -10.121029799040915], [2, -11.917698965880655, -23.17711662602097], [3, -31.81167947898398, -16.7985673023331]], [12.849049222879723, -15.326510824972983]], [[[1, 10.48157743234859, 5.692957082575485], [2, -22.31488473554935, -5.389184118551409], [3, -40.81803984305378, -2.4703329790238118]], [12.849049222879723, -15.326510824972983]], [[[0, 10.591050242096598, -39.2051798967113], [1, -3.5675572049297553, 22.849456408289125], [2, -38.39251065320351, 7.288990306029511]], [12.849049222879723, -15.326510824972983]], [[[0, -3.6225556479370766, -25.58006865235512]], [-7.8874682868419965, -18.379005523261092]], [[[0, 1.9784503557879374, -6.5025974151499]], [-7.8874682868419965, -18.379005523261092]], [[[0, 10.050665232782423, 11.026385307998742]], [-17.82919359778298, 9.062000642947142]], [[[0, 26.526838150174818, -0.22563393232425621], [4, -33.70303936886652, 2.880339841013677]], [-17.82919359778298, 9.062000642947142]]]\n",
    "\n",
    "##  Test Case 1\n",
    "##\n",
    "# Estimated Pose(s):\n",
    "#     [50.000, 50.000]\n",
    "#     [37.858, 33.921]\n",
    "#     [25.905, 18.268]\n",
    "#     [13.524, 2.224]\n",
    "#     [27.912, 16.886]\n",
    "#     [42.250, 30.994]\n",
    "#     [55.992, 44.886]\n",
    "#     [70.749, 59.867]\n",
    "#     [85.371, 75.230]\n",
    "#     [73.831, 92.354]\n",
    "#     [53.406, 96.465]\n",
    "#     [34.370, 100.134]\n",
    "#     [48.346, 83.952]\n",
    "#     [60.494, 68.338]\n",
    "#     [73.648, 53.082]\n",
    "#     [86.733, 38.197]\n",
    "#     [79.983, 20.324]\n",
    "#     [72.515, 2.837]\n",
    "#     [54.993, 13.221]\n",
    "#     [37.164, 22.283]\n",
    "\n",
    "\n",
    "# Estimated Landmarks:\n",
    "#     [82.679, 13.435]\n",
    "#     [70.417, 74.203]\n",
    "#     [36.688, 61.431]\n",
    "#     [18.705, 66.136]\n",
    "#     [20.437, 16.983]\n",
    "\n",
    "\n",
    "### Uncomment the following three lines for test case 1 and compare the output to the values above ###\n",
    "\n",
    "# mu_1 = slam(test_data1, 20, 5, 100.0, 2.0, 2.0)\n",
    "# poses, landmarks = get_poses_landmarks(mu_1, 20)\n",
    "# print_all(poses, landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the data and estimated outputs for test case 2\n",
    "\n",
    "test_data2 = [[[[0, 26.543274387283322, -6.262538160312672], [3, 9.937396825799755, -9.128540360867689]], [18.92765331253674, -6.460955043986683]], [[[0, 7.706544739722961, -3.758467215445748], [1, 17.03954411948937, 31.705489938553438], [3, -11.61731288777497, -6.64964096716416]], [18.92765331253674, -6.460955043986683]], [[[0, -12.35130507136378, 2.585119104239249], [1, -2.563534536165313, 38.22159657838369], [3, -26.961236804740935, -0.4802312626141525]], [-11.167066095509824, 16.592065417497455]], [[[0, 1.4138633151721272, -13.912454837810632], [1, 8.087721200818589, 20.51845934354381], [3, -17.091723454402302, -16.521500551709707], [4, -7.414211721400232, 38.09191602674439]], [-11.167066095509824, 16.592065417497455]], [[[0, 12.886743222179561, -28.703968411636318], [1, 21.660953298391387, 3.4912891084614914], [3, -6.401401414569506, -32.321583037341625], [4, 5.034079343639034, 23.102207946092893]], [-11.167066095509824, 16.592065417497455]], [[[1, 31.126317672358578, -10.036784369535214], [2, -38.70878528420893, 7.4987265861424595], [4, 17.977218575473767, 6.150889254289742]], [-6.595520680493778, -18.88118393939265]], [[[1, 41.82460922922086, 7.847527392202475], [3, 15.711709540417502, -30.34633659912818]], [-6.595520680493778, -18.88118393939265]], [[[0, 40.18454208294434, -6.710999804403755], [3, 23.019508919299156, -10.12110867290604]], [-6.595520680493778, -18.88118393939265]], [[[3, 27.18579315312821, 8.067219022708391]], [-6.595520680493778, -18.88118393939265]], [[], [11.492663265706092, 16.36822198838621]], [[[3, 24.57154567653098, 13.461499960708197]], [11.492663265706092, 16.36822198838621]], [[[0, 31.61945290413707, 0.4272295085799329], [3, 16.97392299158991, -5.274596836133088]], [11.492663265706092, 16.36822198838621]], [[[0, 22.407381798735177, -18.03500068379259], [1, 29.642444125196995, 17.3794951934614], [3, 4.7969752441371645, -21.07505361639969], [4, 14.726069092569372, 32.75999422300078]], [11.492663265706092, 16.36822198838621]], [[[0, 10.705527984670137, -34.589764174299596], [1, 18.58772336795603, -0.20109708164787765], [3, -4.839806195049413, -39.92208742305105], [4, 4.18824810165454, 14.146847823548889]], [11.492663265706092, 16.36822198838621]], [[[1, 5.878492140223764, -19.955352450942357], [4, -7.059505455306587, -0.9740849280550585]], [19.628527845173146, 3.83678180657467]], [[[1, -11.150789592446378, -22.736641053247872], [4, -28.832815721158255, -3.9462962046291388]], [-19.841703647091965, 2.5113335861604362]], [[[1, 8.64427397916182, -20.286336970889053], [4, -5.036917727942285, -6.311739993868336]], [-5.946642674882207, -19.09548221169787]], [[[0, 7.151866679283043, -39.56103232616369], [1, 16.01535401373368, -3.780995345194027], [4, -3.04801331832137, 13.697362774960865]], [-5.946642674882207, -19.09548221169787]], [[[0, 12.872879480504395, -19.707592098123207], [1, 22.236710716903136, 16.331770792606406], [3, -4.841206109583004, -21.24604435851242], [4, 4.27111163223552, 32.25309748614184]], [-5.946642674882207, -19.09548221169787]]] \n",
    "\n",
    "\n",
    "##  Test Case 2\n",
    "##\n",
    "# Estimated Pose(s):\n",
    "#     [50.000, 50.000]\n",
    "#     [69.035, 45.061]\n",
    "#     [87.655, 38.971]\n",
    "#     [76.084, 55.541]\n",
    "#     [64.283, 71.684]\n",
    "#     [52.396, 87.887]\n",
    "#     [44.674, 68.948]\n",
    "#     [37.532, 49.680]\n",
    "#     [31.392, 30.893]\n",
    "#     [24.796, 12.012]\n",
    "#     [33.641, 26.440]\n",
    "#     [43.858, 43.560]\n",
    "#     [54.735, 60.659]\n",
    "#     [65.884, 77.791]\n",
    "#     [77.413, 94.554]\n",
    "#     [96.740, 98.020]\n",
    "#     [76.149, 99.586]\n",
    "#     [70.211, 80.580]\n",
    "#     [64.130, 61.270]\n",
    "#     [58.183, 42.175]\n",
    "\n",
    "\n",
    "# Estimated Landmarks:\n",
    "#     [76.777, 42.415]\n",
    "#     [85.109, 76.850]\n",
    "#     [13.687, 95.386]\n",
    "#     [59.488, 39.149]\n",
    "#     [69.283, 93.654]\n",
    "\n",
    "\n",
    "### Uncomment the following three lines for test case 2 and compare to the values above ###\n",
    "\n",
    "# mu_2 = slam(test_data2, 20, 5, 100.0, 2.0, 2.0)\n",
    "# poses, landmarks = get_poses_landmarks(mu_2, 20)\n",
    "# print_all(poses, landmarks)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
